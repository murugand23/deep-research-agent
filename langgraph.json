{
  "dependencies": ["."],
  "graphs": {
    "deep_research_agent": "src.graph:create_research_graph"
  },
  "env": ".env",
  "configurable": {
    "model": {
      "type": "string",
      "default": "gpt-4o",
      "description": "OpenAI model to use for all LLM calls",
      "enum": ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-3.5-turbo"]
    },
    "temperature": {
      "type": "number",
      "default": 0.1,
      "description": "LLM temperature for researcher (0.0-1.0)"
    },
    "max_search_results": {
      "type": "number",
      "default": 5,
      "description": "Search results per Tavily query"
    },
    "max_questions": {
      "type": "number",
      "default": 10,
      "description": "Max sub-questions generated by planner"
    },
    "max_iterations": {
      "type": "number",
      "default": 2,
      "description": "Max reflection iterations (re-research passes)"
    },
    "chars_per_source": {
      "type": "number",
      "default": 12000,
      "description": "Characters per source during compression"
    }
  }
}
